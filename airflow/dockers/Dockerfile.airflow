FROM apache/airflow:2.8.2-python3.9
USER root

# Install OpenJDK-11
RUN apt update && \
    apt-get install -y openjdk-17-jdk && \
    apt-get install -y ant && \
    apt-get install -y procps && \
    apt-get clean

RUN mkdir -p /opt/spark/jars

ENV HADOOP_VERSION=3.3.4
ENV AWS_JAR_URL=https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_VERSION}/hadoop-aws-${HADOOP_VERSION}.jar
ENV AWS_SDK_JAR_URL=https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.565/aws-java-sdk-bundle-1.12.565.jar
ENV HADOOP_COMMON=https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar

RUN curl https://jdbc.postgresql.org/download/postgresql-42.2.18.jar -o /opt/spark/jars/postgresql-42.2.18.jar
RUN curl -o /opt/spark/jars/hadoop-aws-${HADOOP_VERSION}.jar ${AWS_JAR_URL} && \
    curl -o /opt/spark/jars/aws-java-sdk-bundle-1.12.565.jar ${AWS_SDK_JAR_URL} && \
    curl -o /opt/spark/jars/hadoop-common-3.3.6.jar ${HADOOP_COMMON}
    
ENV JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64
RUN export JAVA_HOME

USER airflow

RUN pip install \
    lxml \
    pyspark==3.3.2 \
    apache-airflow-providers-apache-spark \
    requests==2.31 \
    pandas==1.2.4 \
    python-dotenv==0.20.0 \
    apache-airflow-providers-slack==8.4.0 \
    great-expectations==0.16.13 \
    sqlalchemy-bigquery==1.6.1 \
    google-cloud-bigquery==3.27.0 \
    apache-airflow-providers-amazon==9.1.0 \
    pyarrow

COPY --chown=airflow:root ../../airflow/dags /opt/airflow/dags
COPY ../../commands/entrypoint.sh /opt/airflow/commands/entrypoint.sh
COPY ../../.env /opt/airflow/.env
